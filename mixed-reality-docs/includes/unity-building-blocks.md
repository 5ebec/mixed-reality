# [Available in MRTK](#tab/mrtk)

|  Feature  |  Capabilities  |
| --- | --- |
| [Basic interactions](../mrtk-101.md) | Learn the basics of interacting with objects in immersive space |
| [UX building blocks](https://github.com/Microsoft/MixedRealityToolkit-Unity#ux-building-blocks) | Building blocks for common spatial interactions and UI for MR experiences |
| [Input system](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Overview.html) | MRTK's input system supports various types of devices and controllers |
| [Input simulation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/InputSimulation/InputSimulationService.html) | Simulate various types of input and accelerate design & development |
| [Hand tracking input](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/HandTracking.html) | Build direct interactions with hand mesh and joint |
| [Gaze input](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Gaze.html) | Use head gaze or eye gaze input for your experience |
| [Gesture input](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Gestures.html) | Use gesture input for your experience (HoloLens 1) |
| [Voice command input](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Speech.html) | Use speech input to trigger actions |
| [Dictation input](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Dictation.html) | Dictation allows users to record audio clips and obtain a transcription |
| [Spatial awareness](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/SpatialAwareness/SpatialAwarenessGettingStarted.html) | Make your holographic objects interact with physical environment |
| [MRTK standard shader](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/README_MRTKStandardShader.html) | Create beautiful visual effects with optimized performance for mixed reality |
| [Multi-scene system](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/SceneSystem/SceneSystemGettingStarted.html) | Build a project with multiple scenes and support transition effects |

# [Standalone features](#tab/standalone)

|  Feature  |  Capabilities  |
| --- | --- |
| [Camera](../camera-in-unity.md) | Fully optimize visual quality and hologram stability in your Mixed Reality apps |
| [Coordinate systems](../coordinate-systems-in-unity.md) | Determine the experience scale your application targets |
| [Gaze](../gaze-in-unity.md) | Let users target holograms with by looking at them |
| [Gestures and motion controllers](../gestures-and-motion-controllers-in-unity.md) | Add spatial actions to your users gaze input |
| [Persistence](../persistence-in-unity.md) | Persist holograms locally across different app sessions |
| [Spatial mapping](../spatial-mapping-in-unity.md) | Map your physical space with a virtual mesh overlay to mark the boundaries of your environment |
| [Spatial sound](../spatial-sound-in-unity.md) | Enhance your apps with immersive 3D audio |
| [Text](../text-in-unity.md) | Get sharp, high-quality text that has a manageable size and quality rendering |
| [Voice input](../voice-input-in-unity.md) | Capture spoken keywords, phrases, and dictation from your users|


