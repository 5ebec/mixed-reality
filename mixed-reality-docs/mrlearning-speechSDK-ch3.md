## Lesson 3

In chapter 3, we will add on the Azure Cognitive Services Speech Translation feature to our project and test translating into 3 different languages. 

1. Select the Lunarcom_Base object in the hierarchy and click “Add Component” in the inspector panel. Search for and select “LunarcomTranslationRecognizer.”

![Module4Chapter3step1im](images/module4chapter3step1im.PNG)

> note: Ensure the offline mode simulator is turned back off before testing the Speech-SDK translator. In order to translate, you must be connected to the internet. 

2. Click the dropdown in the “LunarcomTranslationRecognizer” and select the language you would like to translate to.

![Module4Chapter3step2im](images/module4chapter3step2im.PNG)

3. Now, run the application and test the translator by clicking the Satellite button and begin speaking. Press the Satellite button again to stop the recognition. 

> note: Again, before testing, ensure the offline simulator is disabled, as shown in the image below:
>
> ![Module4Chapter3noteim](images/module4chapter3noteim.PNG)

Below is an example of what your scene should look like:

![Module4Chapter3exampleim](images/module4chapter3exampleim.PNG)

## Congratulations

Now  your project can translate your words that you speak into several different languages! Feel free to play around with the languages and test the accuracy. 

[Next Lesson: Speech SDK Lesson 4](placeholderlink)

