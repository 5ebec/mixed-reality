# Optimizing your app for Handsfree

## Handsfree modes
	• Speech 
		○ Commanding 
		○ Assistant
	• Point + commit
		○ Eye gaze + "select" or blink
		○ Head gaze + "select" or dwell 

## Scenarios
Situational disability:
	• Being guided through a task, while hands are busy
	• Referencing materials while your hands are busy
	• Hand fatigue
	• Gloves that can't be tracked
	• Carrying something
	


## Challenges for handsfree: 
- ** Manipulation: handsfree substitutions for manipulation are often neglected. **
		○ Controlling UI elements so they are optimally placed is often a situation-by-situation decision and hard to do without hands.
- ** Awareness: Mechanics are not as 'natural' as hands, so they have to be taught **
		○ Ex. Using voice, then transitioning to pointer or dwell
		○ Ex. Learning wake words and commands
- ** Refactoring UI: Affordances are less 'natural' and have to be optimized for handsfree **
		○ Ex. Dwell affordances are not built-in to typical 2D patterns; 
		○ Ex. Voice targeting is better with object highlighting
		○ Ex. Voice interactions are better with captions that have to be turned on 

		
## Usability Checklist
- ** Gesture replacements become UI elements **
	• Replacement for system gesture, resizing, placing, swipes, taps, etc.

- ** User needs confident control of UI presence, placement, verbosity at all times **
	• Getting UI out of the way
	• Addressing UI that is out of FOV
	• How much I see, where, when

- ** The user needs to understand
	• What mode they are in
	• What they can do in this mode
	• What is the current state
  
- ** How they can transition out **
